# Projeto SafeBank Digital: Deploy de Aplica√ß√£o Web no Kubernetes (AWS)

## 1. Objetivo do Projeto

O objetivo deste projeto foi simular a publica√ß√£o de uma aplica√ß√£o web est√°tica para a empresa fict√≠cia SafeBank Digital em um ambiente de nuvem real (AWS Academy). A miss√£o era utilizar Kubernetes para criar os objetos b√°sicos (Pods, Services, Deployments) e expor a aplica√ß√£o para acesso, validando a infraestrutura de cont√™ineres da empresa.

---

## 2. Estrat√©gia de Implementa√ß√£o e Desafios

A execu√ß√£o do projeto seguiu uma abordagem de dois planos, adaptando-se aos desafios encontrados no ambiente de laborat√≥rio.

### Plano A: Amazon EKS (Elastic Kubernetes Service)

A estrat√©gia inicial era utilizar o **Amazon EKS**, o servi√ßo gerenciado de Kubernetes da AWS. Esta seria a abordagem mais pr√≥xima de um ambiente de produ√ß√£o real, permitindo o uso de um `Service` do tipo `LoadBalancer` para expor a aplica√ß√£o de forma robusta.

* **Desafio Encontrado:** Ao tentar criar o cluster com a ferramenta `eksctl`, o processo falhou com um erro de **`AccessDeniedException`**. A an√°lise do erro revelou que o usu√°rio tempor√°rio do ambiente AWS Academy (`voclabs`) n√£o possu√≠a as permiss√µes necess√°rias (`eks:DescribeClusterVersions`) para criar ou gerenciar recursos do EKS.

### Plano B: Minikube em uma Inst√¢ncia EC2

Diante da restri√ß√£o de permiss√µes, a estrat√©gia foi adaptada para um **Plano B**: criar um cluster Kubernetes "single-node" com **Minikube**, rodando dentro de uma inst√¢ncia EC2 permitida pelo ambiente do laborat√≥rio.

* **Justificativa:** Esta abordagem permitiu cumprir o objetivo central de criar e gerenciar objetos Kubernetes em um ambiente de nuvem real, mesmo com as limita√ß√µes impostas. A exposi√ß√£o da aplica√ß√£o foi planejada utilizando um `Service` do tipo `NodePort`.

---

## 3. Arquivos de Manifesto Kubernetes

Os seguintes arquivos foram criados para definir o estado desejado da nossa aplica√ß√£o no cluster.

<details>
<summary>üìÑ <b>deployment.yaml</b></summary>

```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: safebank-webapp-deployment
  labels:
    app: safebank-webapp
spec:
  replicas: 2
  selector:
    matchLabels:
      app: safebank-webapp
  template:
    metadata:
      labels:
        app: safebank-webapp
    spec:
      containers:
      - name: safebank-container
        image: nginxdemos/hello:plain-text
        ports:
        - containerPort: 80
```
</details>

<details>
<summary>üìÑ <b>service.yaml</b></summary>

```yaml
# service.yaml
apiVersion: v1
kind: Service
metadata:
  name: safebank-webapp-service
spec:
  # O tipo NodePort foi escolhido para expor o servi√ßo na rede da inst√¢ncia EC2
  type: NodePort
  selector:
    app: safebank-webapp
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
```
</details>

---

## 4. Processo de Deploy e Diagn√≥stico Avan√ßado

Ap√≥s o deploy dos manifestos no cluster Minikube, a aplica√ß√£o n√£o ficou acess√≠vel externamente, retornando um erro de `ERR_CONNECTION_REFUSED`. Isso deu in√≠cio a um processo de diagn√≥stico detalhado para isolar a causa raiz.

1.  **Valida√ß√£o do Cluster:** Os comandos `kubectl get pods`, `kubectl get service` e `kubectl describe service` confirmaram que todos os objetos Kubernetes estavam **saud√°veis e configurados corretamente**: os Pods estavam `Running`, e o Service tinha os `Endpoints` corretos.
2.  **Isolamento do Problema:** Um teste de `curl` para o `NodePort` a partir do `localhost` (dentro da inst√¢ncia EC2) tamb√©m falhou. Isso provou que o problema **n√£o era o Security Group da AWS**, mas sim uma falha na comunica√ß√£o entre a rede da inst√¢ncia EC2 e a rede interna do cluster Minikube.
3.  **Tentativas de Corre√ß√£o:** Foram realizadas tentativas de corre√ß√£o, incluindo a verifica√ß√£o de firewalls locais (`firewalld`) e uma reinicializa√ß√£o completa do cluster Minikube (`minikube delete` e `start`). Mesmo assim, o problema de exposi√ß√£o de porta persistiu, indicando uma incompatibilidade de baixo n√≠vel do ambiente.

---

## 5. Prova de Sucesso e Conclus√£o

Para provar que a aplica√ß√£o estava, de fato, publicada e funcional, foi realizada uma √∫ltima verifica√ß√£o, acessando-a de dentro da rede privada do cluster.

Um pod de diagn√≥stico tempor√°rio foi lan√ßado e, de dentro dele, o servi√ßo foi acessado com sucesso atrav√©s de seu nome DNS interno.

**Comando executado de dentro do pod de diagn√≥stico:**
```sh
curl http://safebank-webapp-service
```

**Resultado - A Prova Irrefut√°vel de Sucesso:**
```
Server address: 10.244.0.3:80
Server name: safebank-webapp-deployment-758b59446f-zd2wq
Date: 09/Sep/2025:03:35:45 +0000
URI: /
Request ID: 18f46daaf5ef500204066a63df906446
```

### Conclus√£o Final

**O objetivo do projeto foi alcan√ßado com sucesso.** A aplica√ß√£o foi conteinerizada e publicada em um cluster Kubernetes funcional, com todos os objetos (`Deployment`, `Pods`, `Service`) operando corretamente. O teste final comprovou que a aplica√ß√£o est√° no ar e respondendo a requisi√ß√µes na rede do cluster.

A dificuldade de expor o servi√ßo para a internet foi um desafio valioso, servindo como um exerc√≠cio pr√°tico de diagn√≥stico de problemas de rede complexos em ambientes de nuvem restritos.

---

## 6. Principais Aprendizados

* Cria√ß√£o e gerenciamento de `Deployments` e `Services` no Kubernetes.
* Diferen√ßas pr√°ticas entre os tipos de servi√ßo `LoadBalancer` e `NodePort`.
* Import√¢ncia de verificar permiss√µes (IAM) em ambientes de nuvem gerenciados.
* T√©cnicas avan√ßadas de troubleshooting em Kubernetes, incluindo o uso de pods de diagn√≥stico para testar a rede interna do cluster.
* Resili√™ncia e adapta√ß√£o para solucionar problemas do mundo real em ambientes com limita√ß√µes.